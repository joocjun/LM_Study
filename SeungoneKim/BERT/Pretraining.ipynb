{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import nltk\n",
    "import random\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "\n",
    "from glob import glob\n",
    "from tensorflow.keras.utils import Progbar\n",
    "\n",
    "import transformers\n",
    "from transformers import TFBertForPreTraining\n",
    "from transformers import TFTrainer\n",
    "from transformers import BertConfig, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2016/mono/OpenSubtitles.raw.$LANG_CODE.gz\n",
      "gzip: can't stat: dataset.txt.gz (dataset.txt.gz.gz): No such file or directory\n",
      "tail: dataset.txt: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "AVAILABLE =  {'af','ar','bg','bn','br','bs','ca','cs',\n",
    "              'da','de','el','en','eo','es','et','eu',\n",
    "              'fa','fi','fr','gl','he','hi','hr','hu',\n",
    "              'hy','id','is','it','ja','ka','kk','ko',\n",
    "              'lt','lv','mk','ml','ms','nl','no','pl',\n",
    "              'pt','pt_br','ro','ru','si','sk','sl','sq',\n",
    "              'sr','sv','ta','te','th','tl','tr','uk',\n",
    "              'ur','vi','ze_en','ze_zh','zh','zh_cn',\n",
    "              'zh_en','zh_tw','zh_zh'}\n",
    "\n",
    "LANG_CODE = \"en\" #@param {type:\"string\"}\n",
    "\n",
    "assert LANG_CODE in AVAILABLE, \"Invalid language code selected\"\n",
    "\n",
    "!wget http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2016/mono/OpenSubtitles.raw.'$LANG_CODE'.gz -O dataset.txt.gz\n",
    "!gzip -d dataset.txt.gz\n",
    "!tail dataset.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForPreTraining.\n",
      "\n",
      "All the layers of TFBertForPreTraining were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForPreTraining for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[  101  7592  1010  2026  3899  2003 10140   102]], shape=(1, 8), dtype=int32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[[ -7.8961954  -7.8105164  -7.7903347 ...  -7.069408   -7.1693287\n",
      "    -4.3589554]\n",
      "  [ -8.446108   -8.440074   -8.504436  ...  -8.062478   -7.990895\n",
      "    -5.715992 ]\n",
      "  [-15.295272  -15.472722  -15.586455  ... -12.985673  -11.703852\n",
      "   -11.429297 ]\n",
      "  ...\n",
      "  [-14.062792  -14.253545  -14.364464  ... -12.715123  -11.1620865\n",
      "   -10.231738 ]\n",
      "  [-10.657623  -10.789212  -11.0402155 ... -10.323338  -10.157843\n",
      "    -3.7721484]\n",
      "  [-11.338303  -11.459005  -11.17674   ...  -9.215169   -9.520874\n",
      "    -9.557125 ]]], shape=(1, 8, 30522), dtype=float32)\n",
      "\n",
      "tf.Tensor([[ 3.3474083 -2.0612679]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertForPreTraining.from_pretrained('bert-base-uncased')\n",
    "input_ids = tf.constant(tokenizer.encode(\"Hello, my dog is cute\",add_special_tokens=True))[None,:]\n",
    "print(input_ids)\n",
    "outputs = model(input_ids)\n",
    "prediction_scores, seq_relationship_scores = outputs[:2]\n",
    "print()\n",
    "print(prediction_scores)\n",
    "print()\n",
    "print(seq_relationship_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk.corpus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-625470ba1adc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbrown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mborn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk.corpus'"
     ]
    }
   ],
   "source": [
    "import nltk.corpus\n",
    "from nltk.corpus import brown\n",
    "born.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size= 52000,\n",
    "    max_position_embeddings= 514,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c26740652db45fa81419a3559677ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e586d8ecc12c43ec88f4f6a67ebd82db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74da21392a540c9b2e32367d0befa8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base',max_len=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM\n",
    "\n",
    "model = RobertaForMaskedLM(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83504416"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LineByLineTextDataset\n",
    "\n",
    "dataset = LineByLineTextDataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
